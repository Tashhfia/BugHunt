{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a6e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hridi\\anaconda3\\envs\\CV2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys, time, numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure the sorth module is imported correctly\n",
    "if 'sorth' in sys.modules:\n",
    "    importlib.reload(sys.modules['sorth'])\n",
    "else:\n",
    "    import sorth                          \n",
    "from sorth import Sort, KalmanBoxTracker, associate_detections_to_trackers\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a591161",
   "metadata": {},
   "source": [
    "### Assign model based on AR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_video(video_path, model, dist_th=120, max_age=12, conf_th=0.20, output_base_dir=\"Output\"):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a single video and save results.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    video_path = Path(video_path)\n",
    "    \n",
    "    # Create output directories\n",
    "    frames_dir = Path(f\"{output_base_dir}/frames/{video_path.stem}\")\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_dir = Path(f\"{output_base_dir}/eval/\")\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize tracker\n",
    "    KalmanBoxTracker.count = 0\n",
    "    tracker = Sort(max_age=max_age, min_hits=1, dist_threshold=dist_th)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    # Colors and font\n",
    "    CLR_DET, CLR_PRED, CLR_TRACK, CLR_LINE = (0,255,0), (255,0,0), (255,0,255), (0,255,255)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    frame_idx, t0 = 0, time.time()\n",
    "    records = []\n",
    "    \n",
    "    print(f\"Processing {video_path.name}...\")\n",
    "    \n",
    "    # Main processing loop\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "            \n",
    "        # YOLO detections\n",
    "        result = model(frame, verbose=False)[0]\n",
    "        xyxy = result.boxes.xyxy.cpu().numpy() if result.boxes else np.empty((0,4))\n",
    "        conf = result.boxes.conf.cpu().numpy() if result.boxes else np.empty((0,))\n",
    "        keep = conf > conf_th\n",
    "        dets = xyxy[keep]\n",
    "        conf = conf[keep]\n",
    "        dets_in = np.hstack([dets, conf[:,None]]) if dets.size else np.empty((0,5))\n",
    "        \n",
    "        # Save Kalman predictions before update\n",
    "        preds_before = []\n",
    "        for trk in tracker.trackers:\n",
    "            pred = trk.predict()[0]\n",
    "            preds_before.append(pred)\n",
    "            \n",
    "        # Run tracker update\n",
    "        tracks = tracker.update(dets_in)\n",
    "        for (x1, y1, x2, y2, tid) in tracks:\n",
    "            cx = round((x1 + x2) / 2, 6)\n",
    "            cy = round((y1 + y2) / 2, 6)\n",
    "            records.append({\n",
    "                \"t\": frame_idx,\n",
    "                \"hexbug\": int(tid),\n",
    "                \"x\": cx,\n",
    "                \"y\": cy\n",
    "            })\n",
    "            \n",
    "        # Draw visualization\n",
    "        canvas = frame.copy()\n",
    "        \n",
    "        # Draw detections (green)\n",
    "        for (x1,y1,x2,y2,sc) in dets_in:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_DET,2)\n",
    "            \n",
    "        # Draw Kalman predictions (blue)\n",
    "        for (x1,y1,x2,y2) in preds_before:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_PRED,1)\n",
    "            \n",
    "        # Draw tracks (magenta)\n",
    "        for (x1,y1,x2,y2,tid) in tracks:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_TRACK,2)\n",
    "            cx,cy = int((x1+x2)/2), int((y1+y2)/2)\n",
    "            cv2.putText(canvas,f\"{int(tid)}\",(cx+5,cy-5),font,0.6,CLR_TRACK,2)\n",
    "            \n",
    "        # Draw match lines (yellow)\n",
    "        if preds_before and dets_in.size:\n",
    "            tmp_trk = np.zeros((len(preds_before),5))\n",
    "            tmp_trk[:,:4] = np.array(preds_before)\n",
    "            matches,_,_ = associate_detections_to_trackers(\n",
    "                dets_in, tmp_trk, dist_threshold=dist_th)\n",
    "            for d,t in matches:\n",
    "                dx,dy = (dets_in[d,0]+dets_in[d,2])/2, (dets_in[d,1]+dets_in[d,3])/2\n",
    "                tx,ty = (preds_before[t][0]+preds_before[t][2])/2, (preds_before[t][1]+preds_before[t][3])/2\n",
    "                cv2.line(canvas,(int(dx),int(dy)),(int(tx),int(ty)),CLR_LINE,1,cv2.LINE_AA)\n",
    "                \n",
    "        cv2.putText(canvas,f\"frame {frame_idx}\",(20,30),font,1,(255,255,255),2)\n",
    "        \n",
    "        # Save frame\n",
    "        cv2.imwrite(str(frames_dir / f\"{frame_idx:05d}.jpg\"), canvas)\n",
    "        frame_idx += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    # Save CSV in correct format to match ground truth structure\n",
    "    csv_path = csv_dir / f\"{video_path.stem}.csv\"\n",
    "    df = pd.DataFrame(records).sort_values(['t', 'hexbug'])\n",
    "    \n",
    "    # Reset index to create the first unnamed column like in ground truth\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Save with index=True to create the first column, but no index_label\n",
    "    df.to_csv(csv_path, index=True)\n",
    "  \n",
    "    \n",
    "    print(f\"{video_path.name}: {len(records)} records, {frame_idx} frames\")\n",
    "    \n",
    "    return {\n",
    "        'video': video_path.name,\n",
    "        'csv_path': csv_path,\n",
    "        'frames_dir': frames_dir,\n",
    "        'num_records': len(records),\n",
    "        'num_frames': frame_idx,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def select_model(video_path, threshold=3, model_m_path=\"models/detection/best.pt\", model_s_path=\"models/detection/best_perspective.pt\"):\n",
    "    \"\"\"\n",
    "    Selects a model based on aspect ratio of the video.\n",
    "    \n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Could not open video\")\n",
    "    \n",
    "    # Read first frame dimensions\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        raise ValueError(\"Could not read frame\")\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    aspect_ratio = h / w\n",
    "    \n",
    "    print(f\"Aspect Ratio: {aspect_ratio:.2f}\")\n",
    "    \n",
    "    if aspect_ratio > threshold:\n",
    "        print(\"Using Model M (stretched video).\")\n",
    "        return YOLO(model_m_path)\n",
    "    else:\n",
    "        print(\"Using Model S (normal video).\")\n",
    "        return YOLO(model_s_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304887f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Pipeline: AR Detection + Model Assignment + Evaluation\n",
    "\n",
    "video_dir = Path(\"Validation\")  # path to test videos\n",
    "output_base_dir = \"Val\"  # output directory\n",
    "\n",
    "# Parameters for evaluation\n",
    "eval_params = {\n",
    "    'dist_th': 120,\n",
    "    'max_age': 12, \n",
    "    'conf_th': 0.20,\n",
    "    'output_base_dir': output_base_dir\n",
    "}\n",
    "\n",
    "print(f\"Parameters: {eval_params}\")\n",
    "print(f\"Output directory: {output_base_dir}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get all video files\n",
    "video_files = sorted(video_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_path in enumerate(video_files, 1):\n",
    "    print(f\"\\n[{i}/{len(video_files)}] Processing {video_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Detect AR and select appropriate model\n",
    "        selected_model = select_model(str(video_path))\n",
    "        \n",
    "        # Step 2: Run evaluation with the selected model\n",
    "        result = evaluate_model_on_video(\n",
    "            video_path=video_path,\n",
    "            model=selected_model,\n",
    "            **eval_params\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {video_path.name}: {e}\")\n",
    "        results.append({\n",
    "            'video': video_path.name,\n",
    "            'error': str(e),\n",
    "            'num_records': 0,\n",
    "            'num_frames': 0,\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4656db38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17079b30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
