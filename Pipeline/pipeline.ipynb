{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a6e197",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hridi\\anaconda3\\envs\\CV2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import importlib, sys, time, numpy as np\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure the sorth module is imported correctly\n",
    "if 'sorth' in sys.modules:\n",
    "    importlib.reload(sys.modules['sorth'])\n",
    "else:\n",
    "    import sorth                          \n",
    "from sorth import Sort, KalmanBoxTracker, associate_detections_to_trackers\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7373b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = YOLO(\"model/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17079b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_video(video_path, model, dist_th=120, max_age=12, conf_th=0.20, output_base_dir=\"Output\"):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a single video and save results.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    video_path = Path(video_path)\n",
    "    \n",
    "    # Create output directories\n",
    "    frames_dir = Path(f\"{output_base_dir}/frames/{video_path.stem}\")\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_dir = Path(f\"{output_base_dir}/eval/\")\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize tracker\n",
    "    KalmanBoxTracker.count = 0\n",
    "    tracker = Sort(max_age=max_age, min_hits=1, dist_threshold=dist_th)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    # Colors and font\n",
    "    CLR_DET, CLR_PRED, CLR_TRACK, CLR_LINE = (0,255,0), (255,0,0), (255,0,255), (0,255,255)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    frame_idx, t0 = 0, time.time()\n",
    "    records = []\n",
    "    \n",
    "    print(f\"Processing {video_path.name}...\")\n",
    "    \n",
    "    # Main processing loop\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "            \n",
    "        # YOLO detections\n",
    "        result = model(frame, verbose=False)[0]\n",
    "        xyxy = result.boxes.xyxy.cpu().numpy() if result.boxes else np.empty((0,4))\n",
    "        conf = result.boxes.conf.cpu().numpy() if result.boxes else np.empty((0,))\n",
    "        keep = conf > conf_th\n",
    "        dets = xyxy[keep]\n",
    "        conf = conf[keep]\n",
    "        dets_in = np.hstack([dets, conf[:,None]]) if dets.size else np.empty((0,5))\n",
    "        \n",
    "        # Save Kalman predictions before update\n",
    "        preds_before = []\n",
    "        for trk in tracker.trackers:\n",
    "            pred = trk.predict()[0]\n",
    "            preds_before.append(pred)\n",
    "            \n",
    "        # Run tracker update\n",
    "        tracks = tracker.update(dets_in)\n",
    "        for (x1, y1, x2, y2, tid) in tracks:\n",
    "            cx = round((x1 + x2) / 2, 6)\n",
    "            cy = round((y1 + y2) / 2, 6)\n",
    "            records.append({\n",
    "                \"t\": frame_idx,\n",
    "                \"hexbug\": int(tid),\n",
    "                \"x\": cx,\n",
    "                \"y\": cy\n",
    "            })\n",
    "            \n",
    "        # Draw visualization\n",
    "        canvas = frame.copy()\n",
    "        \n",
    "        # Draw detections (green)\n",
    "        for (x1,y1,x2,y2,sc) in dets_in:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_DET,2)\n",
    "            \n",
    "        # Draw Kalman predictions (blue)\n",
    "        for (x1,y1,x2,y2) in preds_before:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_PRED,1)\n",
    "            \n",
    "        # Draw tracks (magenta)\n",
    "        for (x1,y1,x2,y2,tid) in tracks:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_TRACK,2)\n",
    "            cx,cy = int((x1+x2)/2), int((y1+y2)/2)\n",
    "            cv2.putText(canvas,f\"{int(tid)}\",(cx+5,cy-5),font,0.6,CLR_TRACK,2)\n",
    "            \n",
    "        # Draw match lines (yellow)\n",
    "        if preds_before and dets_in.size:\n",
    "            tmp_trk = np.zeros((len(preds_before),5))\n",
    "            tmp_trk[:,:4] = np.array(preds_before)\n",
    "            matches,_,_ = associate_detections_to_trackers(\n",
    "                dets_in, tmp_trk, dist_threshold=dist_th)\n",
    "            for d,t in matches:\n",
    "                dx,dy = (dets_in[d,0]+dets_in[d,2])/2, (dets_in[d,1]+dets_in[d,3])/2\n",
    "                tx,ty = (preds_before[t][0]+preds_before[t][2])/2, (preds_before[t][1]+preds_before[t][3])/2\n",
    "                cv2.line(canvas,(int(dx),int(dy)),(int(tx),int(ty)),CLR_LINE,1,cv2.LINE_AA)\n",
    "                \n",
    "        cv2.putText(canvas,f\"frame {frame_idx}\",(20,30),font,1,(255,255,255),2)\n",
    "        \n",
    "        # Save frame\n",
    "        cv2.imwrite(str(frames_dir / f\"{frame_idx:05d}.jpg\"), canvas)\n",
    "        frame_idx += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    # Save CSV in correct format to match ground truth structure\n",
    "    csv_path = csv_dir / f\"{video_path.stem}.csv\"\n",
    "    df = pd.DataFrame(records).sort_values(['t', 'hexbug'])\n",
    "    \n",
    "    # Reset index to create the first unnamed column like in ground truth\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Save with index=True to create the first column, but no index_label\n",
    "    df.to_csv(csv_path, index=True)\n",
    "  \n",
    "    \n",
    "    print(f\"{video_path.name}: {len(records)} records, {frame_idx} frames\")\n",
    "    print(f\"  CSV: {csv_path}\")\n",
    "    print(f\"  Frames: {frames_dir}\")\n",
    "    \n",
    "    return {\n",
    "        'video': video_path.name,\n",
    "        'csv_path': csv_path,\n",
    "        'frames_dir': frames_dir,\n",
    "        'num_records': len(records),\n",
    "        'num_frames': frame_idx,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a01b6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'dist_th': 120, 'max_age': 12, 'conf_th': 0.2, 'output_base_dir': 'Val'}\n",
      "Output directory: Val\n",
      "==================================================\n",
      "Found 5 video files to process\n",
      "\n",
      "[1/5] Processing training011.mp4\n",
      "Processing training011.mp4...\n",
      "training011.mp4: 202 records, 101 frames\n",
      "  CSV: Val\\eval\\training011.csv\n",
      "  Frames: Val\\frames\\training011\n",
      "\n",
      "[2/5] Processing training024.mp4\n",
      "Processing training024.mp4...\n",
      "training024.mp4: 101 records, 101 frames\n",
      "  CSV: Val\\eval\\training024.csv\n",
      "  Frames: Val\\frames\\training024\n",
      "\n",
      "[3/5] Processing training034.mp4\n",
      "Processing training034.mp4...\n",
      "training034.mp4: 303 records, 101 frames\n",
      "  CSV: Val\\eval\\training034.csv\n",
      "  Frames: Val\\frames\\training034\n",
      "\n",
      "[4/5] Processing training071.mp4\n",
      "Processing training071.mp4...\n",
      "training071.mp4: 195 records, 101 frames\n",
      "  CSV: Val\\eval\\training071.csv\n",
      "  Frames: Val\\frames\\training071\n",
      "\n",
      "[5/5] Processing training082.mp4\n",
      "Processing training082.mp4...\n",
      "training082.mp4: 196 records, 101 frames\n",
      "  CSV: Val\\eval\\training082.csv\n",
      "  Frames: Val\\frames\\training082\n"
     ]
    }
   ],
   "source": [
    "video_dir = Path(\"Validation\") # path to test videos\n",
    "output_base1 = \"Val\"  # output dir\n",
    "\n",
    "# Parameters for evaluation\n",
    "eval_params = {\n",
    "    'dist_th': 120,\n",
    "    'max_age': 12, \n",
    "    'conf_th': 0.20,\n",
    "    'output_base_dir': output_base1\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Parameters: {eval_params}\")\n",
    "print(f\"Output directory: {output_base1}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "\n",
    "# Get all video files\n",
    "video_files = sorted(video_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_path in enumerate(video_files, 1):\n",
    "    print(f\"\\n[{i}/{len(video_files)}] Processing {video_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model_on_video(\n",
    "            video_path=video_path,\n",
    "            model=model_1,  # Use model_1, change to model_2 if needed\n",
    "            **eval_params\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {video_path.name}: {e}\")\n",
    "        results.append({\n",
    "            'video': video_path.name,\n",
    "            'error': str(e),\n",
    "            'num_records': 0,\n",
    "            'num_frames': 0,\n",
    "            'fps': 0\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c30135",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6641d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8203b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df317d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f023ec08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de54f21e",
   "metadata": {},
   "source": [
    "## Run with preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d92b9f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_dark(frame_bgr: np.ndarray, thr: int = 80) -> bool:\n",
    "    \"\"\"\n",
    "    Return True if the frame’s median V-channel < thr (0-255 scale).\n",
    "    thr = 80 works well for 8-bit footage where ‘normal’ indoor lighting\n",
    "    has median V around 110-140.\n",
    "    \"\"\"\n",
    "    v = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2HSV)[:, :, 2]\n",
    "    return np.median(v) < thr\n",
    "\n",
    "def normalise_exposure(img_bgr: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    1. 1st–99th-percentile stretch on V channel\n",
    "    2. CLAHE local contrast boost\n",
    "    3. Mild saturation equalisation\n",
    "    \"\"\"\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # ---- 1. robust rescale ---------------------------------------------\n",
    "    v = hsv[:, :, 2].astype(np.float32)\n",
    "    lo, hi = np.percentile(v, (1, 99))\n",
    "    if hi - lo > 1:                       # avoid div-by-zero\n",
    "        v = np.clip((v - lo) * 255.0 / (hi - lo), 0, 255)\n",
    "    hsv[:, :, 2] = v.astype(np.uint8)\n",
    "\n",
    "    # ---- 2. local CLAHE -------------------------------------------------\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    hsv[:, :, 2] = clahe.apply(hsv[:, :, 2])\n",
    "\n",
    "    # ---- 3. balance colour cast ----------------------------------------\n",
    "    hsv[:, :, 1] = cv2.equalizeHist(hsv[:, :, 1])\n",
    "\n",
    "    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8023938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_on_video(video_path, model, dist_th=120, max_age=12, conf_th=0.20, output_base_dir=\"Output\"):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a single video and save results.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the video file\n",
    "        model: YOLO model to use for detection\n",
    "        dist_th: Distance threshold for tracking (pixels)\n",
    "        max_age: Maximum age for tracks\n",
    "        conf_th: Confidence threshold for YOLO detections\n",
    "        output_base_dir: Base directory for outputs\n",
    "    \n",
    "    Returns:\n",
    "        dict: Results including CSV path, frame count, FPS\n",
    "    \"\"\"\n",
    "    \n",
    "    video_path = Path(video_path)\n",
    "    \n",
    "    # Create output directories\n",
    "    frames_dir = Path(f\"{output_base_dir}/frames/{video_path.stem}\")\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    csv_dir = Path(f\"{output_base_dir}/eval/{video_path.stem}\")\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Initialize tracker\n",
    "    KalmanBoxTracker.count = 0\n",
    "    tracker = Sort(max_age=max_age, min_hits=1, dist_threshold=dist_th)\n",
    "    \n",
    "    # Open video\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    \n",
    "    # Colors and font\n",
    "    CLR_DET, CLR_PRED, CLR_TRACK, CLR_LINE = (0,255,0), (255,0,0), (255,0,255), (0,255,255)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    frame_idx, t0 = 0, time.time()\n",
    "    records = []\n",
    "    \n",
    "    print(f\"Processing {video_path.name}...\")\n",
    "    \n",
    "    # Main processing loop\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "        \n",
    "        # Brighten dark frames\n",
    "        if is_dark(frame, thr=80):            # choose your threshold once\n",
    "            frame = normalise_exposure(frame)\n",
    "            \n",
    "        # YOLO detections\n",
    "        result = model(frame, verbose=False)[0]\n",
    "        xyxy = result.boxes.xyxy.cpu().numpy() if result.boxes else np.empty((0,4))\n",
    "        conf = result.boxes.conf.cpu().numpy() if result.boxes else np.empty((0,))\n",
    "        keep = conf > conf_th\n",
    "        dets = xyxy[keep]\n",
    "        conf = conf[keep]\n",
    "        dets_in = np.hstack([dets, conf[:,None]]) if dets.size else np.empty((0,5))\n",
    "        \n",
    "        # Save Kalman predictions before update\n",
    "        preds_before = []\n",
    "        for trk in tracker.trackers:\n",
    "            pred = trk.predict()[0]\n",
    "            preds_before.append(pred)\n",
    "            \n",
    "        # Run tracker update\n",
    "        tracks = tracker.update(dets_in)\n",
    "        for (x1, y1, x2, y2, tid) in tracks:\n",
    "            cx = round((x1 + x2) / 2, 6)\n",
    "            cy = round((y1 + y2) / 2, 6)\n",
    "            records.append({\n",
    "                \"t\": frame_idx,\n",
    "                \"hexbug\": int(tid),\n",
    "                \"x\": cx,\n",
    "                \"y\": cy\n",
    "            })\n",
    "            \n",
    "        # Draw visualization\n",
    "        canvas = frame.copy()\n",
    "        \n",
    "        # Draw detections (green)\n",
    "        for (x1,y1,x2,y2,sc) in dets_in:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_DET,2)\n",
    "            \n",
    "        # Draw Kalman predictions (blue)\n",
    "        for (x1,y1,x2,y2) in preds_before:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_PRED,1)\n",
    "            \n",
    "        # Draw tracks (magenta)\n",
    "        for (x1,y1,x2,y2,tid) in tracks:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_TRACK,2)\n",
    "            cx,cy = int((x1+x2)/2), int((y1+y2)/2)\n",
    "            cv2.putText(canvas,f\"{int(tid)}\",(cx+5,cy-5),font,0.6,CLR_TRACK,2)\n",
    "            \n",
    "        # Draw match lines (yellow)\n",
    "        if preds_before and dets_in.size:\n",
    "            tmp_trk = np.zeros((len(preds_before),5))\n",
    "            tmp_trk[:,:4] = np.array(preds_before)\n",
    "            matches,_,_ = associate_detections_to_trackers(\n",
    "                dets_in, tmp_trk, dist_threshold=dist_th)\n",
    "            for d,t in matches:\n",
    "                dx,dy = (dets_in[d,0]+dets_in[d,2])/2, (dets_in[d,1]+dets_in[d,3])/2\n",
    "                tx,ty = (preds_before[t][0]+preds_before[t][2])/2, (preds_before[t][1]+preds_before[t][3])/2\n",
    "                cv2.line(canvas,(int(dx),int(dy)),(int(tx),int(ty)),CLR_LINE,1,cv2.LINE_AA)\n",
    "                \n",
    "        cv2.putText(canvas,f\"frame {frame_idx}\",(20,30),font,1,(255,255,255),2)\n",
    "        \n",
    "        # Save frame\n",
    "        cv2.imwrite(str(frames_dir / f\"{frame_idx:05d}.jpg\"), canvas)\n",
    "        frame_idx += 1\n",
    "        \n",
    "    cap.release()\n",
    "    \n",
    "    # Save CSV in correct format to match ground truth structure\n",
    "    csv_path = csv_dir / f\"{video_path.stem}.csv\"\n",
    "    df = pd.DataFrame(records).sort_values(['t', 'hexbug'])\n",
    "    \n",
    "    # Reset index to create the first unnamed column like in ground truth\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    # Save with index=True to create the first column, but no index_label\n",
    "    df.to_csv(csv_path, index=True)\n",
    "    \n",
    "    # fps = frame_idx / (time.time() - t0)\n",
    "    \n",
    "    print(f\"{video_path.name}: {len(records)} records, {frame_idx} frames\")\n",
    "    print(f\"  CSV: {csv_path}\")\n",
    "    print(f\"  Frames: {frames_dir}\")\n",
    "    \n",
    "    return {\n",
    "        'video': video_path.name,\n",
    "        'csv_path': csv_path,\n",
    "        'frames_dir': frames_dir,\n",
    "        'num_records': len(records),\n",
    "        'num_frames': frame_idx,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f6fcf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'dist_th': 120, 'max_age': 12, 'conf_th': 0.2, 'output_base_dir': 'Output_l'}\n",
      "Output directory: Output_l\n",
      "=*50\n",
      "Found 5 video files to process\n",
      "\n",
      "[1/5] Processing test001.mp4\n",
      "Processing test001.mp4...\n",
      "test001.mp4: 303 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test001\\test001.csv\n",
      "  Frames: Output_l\\frames\\test001\n",
      "\n",
      "[2/5] Processing test002.mp4\n",
      "Processing test002.mp4...\n",
      "test002.mp4: 101 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test002\\test002.csv\n",
      "  Frames: Output_l\\frames\\test002\n",
      "\n",
      "[3/5] Processing test003.mp4\n",
      "Processing test003.mp4...\n",
      "test003.mp4: 390 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test003\\test003.csv\n",
      "  Frames: Output_l\\frames\\test003\n",
      "\n",
      "[4/5] Processing test004.mp4\n",
      "Processing test004.mp4...\n",
      "test004.mp4: 303 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test004\\test004.csv\n",
      "  Frames: Output_l\\frames\\test004\n",
      "\n",
      "[5/5] Processing test005.mp4\n",
      "Processing test005.mp4...\n",
      "test005.mp4: 101 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test005\\test005.csv\n",
      "  Frames: Output_l\\frames\\test005\n"
     ]
    }
   ],
   "source": [
    "video_dir = Path(\"Leaderboard_data\") # path to test videos\n",
    "output_base1 = \"Output_l\"  # output dir\n",
    "\n",
    "# Parameters for evaluation\n",
    "eval_params = {\n",
    "    'dist_th': 120,\n",
    "    'max_age': 12, \n",
    "    'conf_th': 0.20,\n",
    "    'output_base_dir': output_base1\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Parameters: {eval_params}\")\n",
    "print(f\"Output directory: {output_base1}\")\n",
    "print(\"=*50\")\n",
    "\n",
    "\n",
    "# Get all video files\n",
    "video_files = sorted(video_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_path in enumerate(video_files, 1):\n",
    "    print(f\"\\n[{i}/{len(video_files)}] Processing {video_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model_on_video(\n",
    "            video_path=video_path,\n",
    "            model=model_1,  # Use model_1, change to model_2 if needed\n",
    "            **eval_params\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {video_path.name}: {e}\")\n",
    "        results.append({\n",
    "            'video': video_path.name,\n",
    "            'error': str(e),\n",
    "            'num_records': 0,\n",
    "            'num_frames': 0,\n",
    "            'fps': 0\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0922adbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time, cv2, numpy as np, pandas as pd\n",
    "  # ← gives letterbox + scale_boxes\n",
    "\n",
    "# ── helper: quick brightness test ──────────────────────────────\n",
    "def is_dark(bgr, thr=80):\n",
    "    v = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)[:, :, 2]\n",
    "    return np.median(v) < thr\n",
    "\n",
    "def letterbox(img, new_shape=640, color=(114, 114, 114)):\n",
    "    \"\"\"Resize and pad image to meet stride-multiple constraints.\"\"\"\n",
    "    import math, cv2, numpy as np\n",
    "    h, w = img.shape[:2]\n",
    "    if isinstance(new_shape, int):\n",
    "        new_shape = (new_shape, new_shape)\n",
    "\n",
    "    # scale ratio (new / old)  and compute padding\n",
    "    r = min(new_shape[0] / h, new_shape[1] / w)\n",
    "    new_unpad = (int(round(w * r)), int(round(h * r)))\n",
    "    dw, dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]\n",
    "    dw, dh = dw // 2, dh // 2\n",
    "\n",
    "    # resize\n",
    "    if (w, h) != new_unpad:\n",
    "        img = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # pad\n",
    "    img = cv2.copyMakeBorder(img, dh, dh, dw, dw, cv2.BORDER_CONSTANT, value=color)\n",
    "    return img, r, (dw, dh)\n",
    "\n",
    "def scale_boxes(img_shape, boxes, ori_shape, ratio, pad):\n",
    "    \"\"\"Invert letter-box transform on a set of xyxy boxes.\"\"\"\n",
    "    boxes[:, [0, 2]] -= pad[0]\n",
    "    boxes[:, [1, 3]] -= pad[1]\n",
    "    boxes[:, :4] /= ratio\n",
    "    boxes[:, 0::2] = boxes[:, 0::2].clip(0, ori_shape[1])\n",
    "    boxes[:, 1::2] = boxes[:, 1::2].clip(0, ori_shape[0])\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def evaluate_model_on_video(\n",
    "        video_path, model,\n",
    "        dist_th=120, max_age=12, conf_th=0.20,\n",
    "        output_base_dir=\"Output\"):\n",
    "\n",
    "    video_path = Path(video_path)\n",
    "\n",
    "    # ── output dirs ────────────────────────────────────────────\n",
    "    frames_dir = Path(f\"{output_base_dir}/frames/{video_path.stem}\")\n",
    "    frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_dir = Path(f\"{output_base_dir}/eval/{video_path.stem}\")\n",
    "    csv_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    KalmanBoxTracker.count = 0\n",
    "    tracker = Sort(max_age=max_age, min_hits=1, dist_threshold=dist_th)\n",
    "\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    CLR_DET, CLR_PRED, CLR_TRACK, CLR_LINE = (0,255,0), (255,0,0), (255,0,255), (0,255,255)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    frame_idx, records = 0, []\n",
    "    print(f\"Processing {video_path.name} …\")\n",
    "\n",
    "    # ───────────────────────── main loop ───────────────────────\n",
    "    while True:\n",
    "        ok, frame = cap.read()\n",
    "        if not ok:\n",
    "            break\n",
    "\n",
    "        # — 1. optional exposure fix —\n",
    "        if is_dark(frame, thr=80):\n",
    "            frame = normalise_exposure(frame)\n",
    "\n",
    "        # — 2. letter-box to square, feed YOLO —\n",
    "        sq, ratio, (dw, dh) = letterbox(frame, new_shape=640)\n",
    "        yolo_out = model(sq, verbose=False)[0]\n",
    "\n",
    "        # — 3. move boxes back to original frame coords —\n",
    "        boxes = yolo_out.boxes.cpu()\n",
    "        xyxy = boxes.xyxy.numpy()                # (N,4)\n",
    "        conf = boxes.conf.numpy()\n",
    "        xyxy = scale_boxes(sq.shape, xyxy, frame.shape,\n",
    "                               ratio=ratio, pad=(dw, dh))\n",
    "\n",
    "        keep = conf > conf_th\n",
    "        dets_in = np.hstack([xyxy[keep], conf[keep, None]]) if keep.any() else np.empty((0,5))\n",
    "\n",
    "        # — 4. predict & update tracker —\n",
    "        preds_before = [trk.predict()[0] for trk in tracker.trackers]\n",
    "        tracks = tracker.update(dets_in)\n",
    "\n",
    "        # — 5. store centres for CSV —\n",
    "        for (x1, y1, x2, y2, tid) in tracks:\n",
    "            records.append({\"t\": frame_idx,\n",
    "                            \"hexbug\": int(tid),\n",
    "                            \"x\": round((x1+x2)/2, 6),\n",
    "                            \"y\": round((y1+y2)/2, 6)})\n",
    "\n",
    "        # — 6. optional on-screen drawing —\n",
    "        canvas = frame.copy()\n",
    "        for (x1,y1,x2,y2,sc) in dets_in:\n",
    "            cv2.rectangle(canvas, (int(x1),int(y1)), (int(x2),int(y2)), CLR_DET, 2)\n",
    "        for (x1,y1,x2,y2) in preds_before:\n",
    "            cv2.rectangle(canvas, (int(x1),int(y1)), (int(x2),int(y2)), CLR_PRED, 1)\n",
    "        for (x1,y1,x2,y2,tid) in tracks:\n",
    "            cv2.rectangle(canvas,(int(x1),int(y1)),(int(x2),int(y2)), CLR_TRACK,2)\n",
    "            cx,cy = int((x1+x2)/2), int((y1+y2)/2)\n",
    "            cv2.putText(canvas,f\"{int(tid)}\",(cx+5,cy-5),font,0.6,CLR_TRACK,2)\n",
    "\n",
    "        # yellow match lines (optional eye-candy)\n",
    "        if preds_before and dets_in.size:\n",
    "            tmp = np.zeros((len(preds_before),5)); tmp[:,:4] = np.array(preds_before)\n",
    "            matches,_,_ = associate_detections_to_trackers(dets_in, tmp, dist_threshold=dist_th)\n",
    "            for d,t in matches:\n",
    "                dx,dy = (dets_in[d,0]+dets_in[d,2])/2, (dets_in[d,1]+dets_in[d,3])/2\n",
    "                tx,ty = (preds_before[t][0]+preds_before[t][2])/2, (preds_before[t][1]+preds_before[t][3])/2\n",
    "                cv2.line(canvas,(int(dx),int(dy)),(int(tx),int(ty)),CLR_LINE,1,cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(canvas,f\"frame {frame_idx}\",(20,30),font,1,(255,255,255),2)\n",
    "        cv2.imwrite(str(frames_dir / f\"{frame_idx:05d}.jpg\"), canvas)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    # ── write CSV ──────────────────────────────────────────────\n",
    "    df = (pd.DataFrame(records)\n",
    "            .sort_values(['t','hexbug'])\n",
    "            .reset_index(drop=True))\n",
    "    csv_path = csv_dir / f\"{video_path.stem}.csv\"\n",
    "    df.to_csv(csv_path, index=True)      # keeps first ‘index’ column\n",
    "\n",
    "    print(f\"{video_path.name}: {len(records)} records, {frame_idx} frames\")\n",
    "    print(f\"  CSV: {csv_path}\")\n",
    "    print(f\"  Frames: {frames_dir}\")\n",
    "\n",
    "    return {\"video\": video_path.name,\n",
    "            \"csv_path\": csv_path,\n",
    "            \"frames_dir\": frames_dir,\n",
    "            \"num_records\": len(records),\n",
    "            \"num_frames\": frame_idx}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02cf83cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'dist_th': 120, 'max_age': 12, 'conf_th': 0.2, 'output_base_dir': 'Output_l'}\n",
      "Output directory: Output_l\n",
      "=*50\n",
      "Found 5 video files to process\n",
      "\n",
      "[1/5] Processing test001.mp4\n",
      "Processing test001.mp4 …\n",
      "test001.mp4: 303 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test001\\test001.csv\n",
      "  Frames: Output_l\\frames\\test001\n",
      "\n",
      "[2/5] Processing test002.mp4\n",
      "Processing test002.mp4 …\n",
      "test002.mp4: 101 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test002\\test002.csv\n",
      "  Frames: Output_l\\frames\\test002\n",
      "\n",
      "[3/5] Processing test003.mp4\n",
      "Processing test003.mp4 …\n",
      "test003.mp4: 400 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test003\\test003.csv\n",
      "  Frames: Output_l\\frames\\test003\n",
      "\n",
      "[4/5] Processing test004.mp4\n",
      "Processing test004.mp4 …\n",
      "test004.mp4: 303 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test004\\test004.csv\n",
      "  Frames: Output_l\\frames\\test004\n",
      "\n",
      "[5/5] Processing test005.mp4\n",
      "Processing test005.mp4 …\n",
      "test005.mp4: 101 records, 101 frames\n",
      "  CSV: Output_l\\eval\\test005\\test005.csv\n",
      "  Frames: Output_l\\frames\\test005\n"
     ]
    }
   ],
   "source": [
    "video_dir = Path(\"Leaderboard_data\") # path to test videos\n",
    "output_base1 = \"Output_l\"  # output dir\n",
    "\n",
    "# Parameters for evaluation\n",
    "eval_params = {\n",
    "    'dist_th': 120,\n",
    "    'max_age': 12, \n",
    "    'conf_th': 0.20,\n",
    "    'output_base_dir': output_base1\n",
    "}\n",
    "\n",
    "\n",
    "print(f\"Parameters: {eval_params}\")\n",
    "print(f\"Output directory: {output_base1}\")\n",
    "print(\"=*50\")\n",
    "\n",
    "\n",
    "# Get all video files\n",
    "video_files = sorted(video_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_path in enumerate(video_files, 1):\n",
    "    print(f\"\\n[{i}/{len(video_files)}] Processing {video_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        result = evaluate_model_on_video(\n",
    "            video_path=video_path,\n",
    "            model=model_1,  # Use model_1, change to model_2 if needed\n",
    "            **eval_params\n",
    "        )\n",
    "        results.append(result)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error processing {video_path.name}: {e}\")\n",
    "        results.append({\n",
    "            'video': video_path.name,\n",
    "            'error': str(e),\n",
    "            'num_records': 0,\n",
    "            'num_frames': 0,\n",
    "            'fps': 0\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68d1537c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def select_model(video_path, threshold=3):\n",
    "    \"\"\"\n",
    "    Selects a model based on aspect ratio of the video.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to input video\n",
    "        model_M: Model for stretched (tall) videos\n",
    "        model_S: Model for normal videos\n",
    "        threshold (float): Aspect ratio threshold to decide stretched vs normal\n",
    "    \n",
    "    Returns:\n",
    "        selected_model\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        raise ValueError(\"Could not open video\")\n",
    "    \n",
    "    # Read first frame dimensions\n",
    "    ret, frame = cap.read()\n",
    "    cap.release()\n",
    "    \n",
    "    if not ret:\n",
    "        raise ValueError(\"Could not read frame\")\n",
    "    \n",
    "    h, w = frame.shape[:2]\n",
    "    aspect_ratio = h / w\n",
    "    \n",
    "    print(f\"Aspect Ratio: {aspect_ratio:.2f}\")\n",
    "    \n",
    "    if aspect_ratio > threshold:\n",
    "        print(\"Using Model M (stretched video).\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Using Model S (normal video).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "505f86f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 video files to process\n",
      "\n",
      "[1/20] Processing test001.mp4\n",
      "Aspect Ratio: 1.41\n",
      "Using Model S (normal video).\n",
      "\n",
      "[2/20] Processing test002.mp4\n",
      "Aspect Ratio: 1.31\n",
      "Using Model S (normal video).\n",
      "\n",
      "[3/20] Processing test003.mp4\n",
      "Aspect Ratio: 0.69\n",
      "Using Model S (normal video).\n",
      "\n",
      "[4/20] Processing test004.mp4\n",
      "Aspect Ratio: 1.12\n",
      "Using Model S (normal video).\n",
      "\n",
      "[5/20] Processing test005.mp4\n",
      "Aspect Ratio: 3.57\n",
      "Using Model M (stretched video).\n",
      "\n",
      "[6/20] Processing test006.mp4\n",
      "Aspect Ratio: 1.30\n",
      "Using Model S (normal video).\n",
      "\n",
      "[7/20] Processing test007.mp4\n",
      "Aspect Ratio: 0.88\n",
      "Using Model S (normal video).\n",
      "\n",
      "[8/20] Processing test008.mp4\n",
      "Aspect Ratio: 1.71\n",
      "Using Model S (normal video).\n",
      "\n",
      "[9/20] Processing test009.mp4\n",
      "Aspect Ratio: 0.56\n",
      "Using Model S (normal video).\n",
      "\n",
      "[10/20] Processing test010.mp4\n",
      "Aspect Ratio: 1.28\n",
      "Using Model S (normal video).\n",
      "\n",
      "[11/20] Processing test011.mp4\n",
      "Aspect Ratio: 0.67\n",
      "Using Model S (normal video).\n",
      "\n",
      "[12/20] Processing test012.mp4\n",
      "Aspect Ratio: 1.30\n",
      "Using Model S (normal video).\n",
      "\n",
      "[13/20] Processing test013.mp4\n",
      "Aspect Ratio: 0.91\n",
      "Using Model S (normal video).\n",
      "\n",
      "[14/20] Processing test014.mp4\n",
      "Aspect Ratio: 1.30\n",
      "Using Model S (normal video).\n",
      "\n",
      "[15/20] Processing test015.mp4\n",
      "Aspect Ratio: 1.29\n",
      "Using Model S (normal video).\n",
      "\n",
      "[16/20] Processing test016.mp4\n",
      "Aspect Ratio: 0.56\n",
      "Using Model S (normal video).\n",
      "\n",
      "[17/20] Processing test017.mp4\n",
      "Aspect Ratio: 1.11\n",
      "Using Model S (normal video).\n",
      "\n",
      "[18/20] Processing test018.mp4\n",
      "Aspect Ratio: 0.90\n",
      "Using Model S (normal video).\n",
      "\n",
      "[19/20] Processing test019.mp4\n",
      "Aspect Ratio: 0.98\n",
      "Using Model S (normal video).\n",
      "\n",
      "[20/20] Processing test020.mp4\n",
      "Aspect Ratio: 1.42\n",
      "Using Model S (normal video).\n"
     ]
    }
   ],
   "source": [
    "# Get all video files\n",
    "video_dir = Path(\"Add\") # path to test videos\n",
    "video_files = sorted(video_dir.glob(\"*.mp4\"))\n",
    "print(f\"Found {len(video_files)} video files to process\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, video_path in enumerate(video_files, 1):\n",
    "    print(f\"\\n[{i}/{len(video_files)}] Processing {video_path.name}\")\n",
    "    selected_model = select_model(video_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51cef89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
